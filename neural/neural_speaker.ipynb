{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_speaker.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2eufkp6eDB7rxezigqLHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limpa105/RegexPlus/blob/neural_stuff/neural/neural_speaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hypothesis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enzDIocNc2WO",
        "outputId": "b987b42c-2236-4929-bc5f-6f78e4e25f75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hypothesis\n",
            "  Downloading hypothesis-6.50.1-py3-none-any.whl (388 kB)\n",
            "\u001b[K     |████████████████████████████████| 388 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting exceptiongroup>=1.0.0rc8\n",
            "  Downloading exceptiongroup-1.0.0rc8-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis) (21.4.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis) (2.4.0)\n",
            "Installing collected packages: exceptiongroup, hypothesis\n",
            "Successfully installed exceptiongroup-1.0.0rc8 hypothesis-6.50.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "import random \n",
        "from numpy.random import choice\n",
        "from scipy.stats import skewnorm\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import hypothesis\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "qyCUEZQVQeB6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(num_examples: int, max_size:int, regex_things:list) -> list:\n",
        "  examples = [ [ regex_things[random.randint(0,len(regex_things)-1)] for  i in range(random.randint(1,max_size))] for k in range(num_examples)]\n",
        "  return examples\n",
        "  \n",
        "def generate_training_data_pairs(training_data: list) -> list:\n",
        "  return [(i, hypothesis.strategies.from_regex('^' + ''.join(i) + '$').example().strip()) for i in training_data]"
      ],
      "metadata": {
        "id": "CauyBJfOSV_D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3RMj6JRZPgsS"
      },
      "outputs": [],
      "source": [
        "# make the language \n",
        "# first iteration = very restricted language no optionals no constants\n",
        "regex_things : list = ['[0-9]','[a-z]','[A-Z]','[a-zA-Z]', '[a-zA-Z0-9]']\n",
        "ascii_char : list = list(string.printable)[:95]\n",
        "special_char = ['.', '\\\\', '+', '*', ')', '(', '?' ]\n",
        "#regex_things = regex_things + [ i for i in ascii_char if i not in special_char]\n",
        "#regex_things = regex_things + [ '\\\\' + i for i in special_char]\n",
        "# takes some time to run \n",
        "# TODO: Write this into a file and read from a filwe\n",
        "training_data = generate_training_data(1000, 10, regex_things)\n",
        "pairs = generate_training_data_pairs(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "# constructing langiage using \n",
        "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "      \n",
        "    def addList(self, list_words):\n",
        "        for word in list_words:\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "dwqhuAbfU-B6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 12\n",
        "def readLangs(lang1: list, lang2:list, reverse=False):\n",
        "  input_lang = Lang('regex')\n",
        "  output_lang = Lang('english')\n",
        "  input_lang.addList(lang1)\n",
        "  output_lang.addList(lang2)\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name, output_lang.n_words)\n",
        "  return input_lang, output_lang\n"
      ],
      "metadata": {
        "id": "FW8IuHQQYzHE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang = readLangs(regex_things, ascii_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pIWLJ71Zj8K",
        "outputId": "6bbaa1d8-3145-4dff-cdc0-c84e0b412bf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "regex 7\n",
            "english 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model code also taken from \n",
        "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "slvzG5NTaop4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromList(lang, char_list):\n",
        "    return [lang.word2index[word] for word in char_list]\n",
        "\n",
        "\n",
        "def tensorFromList(lang, char_list):\n",
        "    indexes = indexesFromList(lang, char_list)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromList(input_lang, pair[0])\n",
        "    target_tensor = tensorFromList(output_lang, list(pair[1]))\n",
        "    return (input_tensor, target_tensor)\n"
      ],
      "metadata": {
        "id": "FvtwLz9rdjid"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "FB4PuJvkhuEO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "-86xIPkEkfZm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "lT5-lhuNksFQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "vaRVlRGokuPj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromList(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "5bIfNZX-kyrY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 30000, print_every=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk6u5Rf9k3os",
        "outputId": "90704f73-f5e6-448a-fdfe-e53e661a6ed8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 13s (- 6m 26s) (1000 3%) 2.9813\n",
            "0m 25s (- 5m 52s) (2000 6%) 3.2510\n",
            "0m 37s (- 5m 40s) (3000 10%) 3.1910\n",
            "0m 49s (- 5m 23s) (4000 13%) 3.1228\n",
            "1m 1s (- 5m 9s) (5000 16%) 3.0718\n",
            "1m 13s (- 4m 54s) (6000 20%) 3.0227\n",
            "1m 25s (- 4m 41s) (7000 23%) 2.9434\n",
            "1m 37s (- 4m 28s) (8000 26%) 2.9148\n",
            "1m 49s (- 4m 16s) (9000 30%) 2.8696\n",
            "2m 2s (- 4m 4s) (10000 33%) 2.7986\n",
            "2m 14s (- 3m 52s) (11000 36%) 2.6889\n",
            "2m 27s (- 3m 40s) (12000 40%) 2.6434\n",
            "2m 39s (- 3m 28s) (13000 43%) 2.5758\n",
            "2m 51s (- 3m 16s) (14000 46%) 2.4474\n",
            "3m 4s (- 3m 4s) (15000 50%) 2.3789\n",
            "3m 20s (- 2m 55s) (16000 53%) 2.2746\n",
            "3m 34s (- 2m 44s) (17000 56%) 2.2192\n",
            "3m 47s (- 2m 31s) (18000 60%) 2.1034\n",
            "4m 0s (- 2m 19s) (19000 63%) 1.9971\n",
            "4m 12s (- 2m 6s) (20000 66%) 1.8478\n",
            "4m 25s (- 1m 53s) (21000 70%) 1.7082\n",
            "4m 38s (- 1m 41s) (22000 73%) 1.6896\n",
            "4m 50s (- 1m 28s) (23000 76%) 1.5565\n",
            "5m 3s (- 1m 15s) (24000 80%) 1.4591\n",
            "5m 15s (- 1m 3s) (25000 83%) 1.3903\n",
            "5m 28s (- 0m 50s) (26000 86%) 1.2677\n",
            "5m 40s (- 0m 37s) (27000 90%) 1.2353\n",
            "5m 53s (- 0m 25s) (28000 93%) 1.1309\n",
            "6m 5s (- 0m 12s) (29000 96%) 1.0245\n",
            "6m 17s (- 0m 0s) (30000 100%) 1.0071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(encoder1, attn_decoder1, ['[0-9]', '[a-z]', '[A-Z]'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc49gfuVnjRT",
        "outputId": "9679bd6b-ccae-4945-ecf0-fddcab5b77e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['1', 'b', 'B', '<EOS>'],\n",
              " tensor([[8.8615e-12, 3.1665e-11, 1.0000e+00, 1.2885e-09, 3.0413e-06, 9.5006e-16,\n",
              "          2.7599e-15, 1.5137e-17, 3.5965e-11, 1.5679e-12, 8.3069e-12, 1.1674e-11],\n",
              "         [2.5416e-16, 8.2426e-16, 2.0843e-14, 3.4032e-15, 1.0000e+00, 2.1677e-13,\n",
              "          1.5051e-21, 9.7665e-27, 7.8146e-14, 5.2968e-17, 5.1381e-16, 1.1139e-15],\n",
              "         [3.8029e-11, 4.4879e-11, 1.0111e-09, 3.7400e-10, 1.0000e+00, 2.8441e-10,\n",
              "          5.2547e-13, 9.6653e-17, 6.0517e-10, 1.9397e-11, 3.5769e-11, 5.9174e-11],\n",
              "         [2.6312e-06, 1.6109e-06, 3.1796e-07, 4.7060e-06, 3.6137e-04, 9.9952e-01,\n",
              "          3.5089e-09, 3.3599e-08, 6.1721e-07, 1.0055e-04, 2.2303e-06, 3.0490e-06]]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}